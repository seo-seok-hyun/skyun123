{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Decision Tree Regression\n\n참고: XGBoost와 사이킷런을 활용한 그레이디언트 부스팅 (한빛미디어, 2022)","metadata":{"id":"aTGOHpJlVlSJ"}},{"cell_type":"markdown","source":"* 결정 트리는 가지(branch) 분할을 통해 데이터를 두 개의 노드(node)로 나눔\n* 가지 분할은 예측을 만드는 리프 노드(leaf node)까지 계속됨","metadata":{}},{"cell_type":"markdown","source":"### 1. 필요한 Python 라이브러리 Import 하기","metadata":{"id":"tG15ewmCVlSS"}},{"cell_type":"code","source":"# 판다스와 넘파이를 임포트합니다.\nimport pandas as pd\nimport numpy as np\n\n# train_test_split 함수를 임포트합니다.\nfrom sklearn.model_selection import train_test_split\n\n# DecisionTreeRegressor를 임포트합니다.\nfrom sklearn.tree import DecisionTreeRegressor\n\n# cross_val_score를 임포트합니다.\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn import tree\nimport matplotlib.pyplot as plt\n\n# 경고를 끕니다.\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"VLXwzmWFVlSS","trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. 자전거 대여 데이터 읽기","metadata":{"id":"KGtAHaf2VlSX"}},{"cell_type":"code","source":"# bike_rentals_cleaned 데이터셋을 로드합니다.\ndf_bikes = pd.read_csv(\"bike_rentals_cleaned.csv\")\ndf_bikes","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# describe()를 활용한 통계특성 확인하기\ndf_bikes.describe()","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 데이터를 X와 y로 나눕니다.\nX_bikes = df_bikes.iloc[:, :-1]\nX_bikes","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_bikes = df_bikes.iloc[:, -1]\ny_bikes","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. DecisionTreeRegressor를 활용한 K-폴드 교차검증 시행","metadata":{}},{"cell_type":"code","source":"# DecisionTreeRegressor 객체를 만듭니다.\nreg = DecisionTreeRegressor(random_state=2)\nreg","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 평균 제곱 오차로 교차 검증 점수를 계산합니다. CV=5는 전체 데이터를 5개영역으로 구분하여 교차검증 시행\nscores = cross_val_score(reg, X_bikes, y_bikes, scoring=\"neg_mean_squared_error\", cv=5)\nscores","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4. K-폴드 교차검증의 결과 RMSE 산정","metadata":{}},{"cell_type":"code","source":"# 제곱근을 계산합니다.\nrmse = np.sqrt(-scores)\nrmse","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5번 교차검증한 RMSE의 평균을 출력합니다.\nprint(\"RMSE 평균: %0.2f\" % (rmse.mean()))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41l3Uv6nVlSY","outputId":"04efbe3d-8a64-44c1-9b0f-108d09f91c97","trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5. 모델 개발 및 성능 검증","metadata":{}},{"cell_type":"code","source":"# 데이터를 훈련 세트와 테스트 세트로 나눕니다.\nX_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, random_state=2)","metadata":{"id":"VAlwnG13VlSY","trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DecisionTreeRegressor를 훈련 세트에서 훈련하고 점수를 계산합니다.\nreg = DecisionTreeRegressor()\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_train)","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = plt.figure(figsize=(16, 5))\nax = fig.add_subplot()\nax.scatter(\n    X_train.index, y_train, label=\"Real Bike Rental Data\", s=10, c=\"b\", alpha=0.5\n)\nax.scatter(\n    X_train.index, y_pred, label=\"Predicted Bike Rental Data\", s=10, c=\"r\", alpha=0.5\n)\nax.set_ylabel(\"Bike rental\")\nax.grid()\nfig.legend(loc=\"upper left\", bbox_to_anchor=(0.13, 0.85))","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = plt.figure(figsize=(5, 5))\nax = fig.add_subplot()\nax.scatter(y_train, y_pred, s=10, c=\"b\", alpha=0.5)\nax.set_xlabel(\"Real Bike Rental Data\")\nax.set_ylabel(\"Predicted Bike Rental Data\")\nax.grid()\nfig.legend(loc=\"upper left\", bbox_to_anchor=(0.13, 0.85))","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DecisionTreeRegressor를 훈련 세트에서 훈련하고 점수를 계산합니다.\n# 위의 그래프를 보면 모든 데이터 포인트를 완벽하게 맞추고 있음\n# 위의 교차검증 결과 RMSE=1233.36과 비교시 과적합되었다고 볼 수 있음\nfrom sklearn.metrics import mean_squared_error\n\nreg_mse = mean_squared_error(y_train, y_pred)\nreg_rmse = np.sqrt(reg_mse)\nreg_rmse","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgWQFHjhVlSZ","outputId":"96176c9a-4cd9-45c1-a0fe-e4b2fb4e0c86","trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DecisionTreeRegressor의 가지분류에 대한 시각화\nplt.figure(figsize=(30, 10))\ntree.plot_tree(reg, proportion=True, max_depth=2)\nplt.show()","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6. 하이퍼파라미터 튜닝을 통한 과적합 해결: GridSearchCV","metadata":{}},{"cell_type":"code","source":"# GridSearchCV를 임포트합니다.\nfrom sklearn.model_selection import GridSearchCV\n\n# max_depth 매개변수를 선택합니다.\nparams = {\"max_depth\": [None, 2, 3, 4, 6, 8, 10, 20]}\n\n# 회귀 모델을 만듭니다.\nreg = DecisionTreeRegressor(random_state=2)\n\n# GridSearchCV 객체를 초기화합니다.\ngrid_reg = GridSearchCV(\n    reg,\n    params,\n    scoring=\"neg_mean_squared_error\",\n    cv=5,\n    return_train_score=True,\n    n_jobs=-1,\n)\n\n# X_train와 y_train로 그리드 서치를 수행합니다.\ngrid_reg.fit(X_train, y_train)\n\n# 최상의 매개변수를 추출합니다.\nbest_params = grid_reg.best_params_\n\n# 최상의 매개변수를 출력합니다.\nprint(\"최상의 매개변수:\", best_params)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Lyki0uTVlSa","outputId":"e048aa4d-d55a-4500-8a0c-b74bdb278684","trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"grid_reg.cv_results_[\"mean_test_score\"]","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 최상의 점수를 계산합니다.\nbest_score = np.sqrt(-grid_reg.best_score_)\n\n# 최상의 점수를 출력합니다.\nprint(\"훈련 점수: {:.3f}\".format(best_score))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylZhKPNYVlSa","outputId":"8dc2325a-692d-4841-9967-6428a35d0508","scrolled":true,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 최상의 모델을 추출합니다.\nbest_model = grid_reg.best_estimator_\n\n# 테스트 세트에서 예측을 만듭니다.\ny_pred = best_model.predict(X_test)\n\n# mean_squared_error를 임포트합니다.\nfrom sklearn.metrics import mean_squared_error\n\n# 테스트 세트의 제곱근 오차를 계산합니다.\nrmse_test = mean_squared_error(y_test, y_pred) ** 0.5\n\n# 테스트 세트 점수를 출력합니다.\nprint(\"테스트 점수: {:.3f}\".format(rmse_test))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9U_O4ivVlSb","outputId":"547b36a7-e3e3-44ce-e69b-86acdffaa57a","trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = plt.figure(figsize=(5, 5))\nax = fig.add_subplot()\nax.scatter(y_test, y_pred, s=15, c=\"b\", alpha=0.5)\nax.set_xlabel(\"Real Bike Rental Data\")\nax.set_ylabel(\"Predicted Bike Rental Data\")\nax.set_xlim([0, 9000])\nax.set_ylim([0, 9000])\nax.grid()\nfig.legend(loc=\"upper left\", bbox_to_anchor=(0.13, 0.85))","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 7. 하이퍼파라미터 튜닝(min_samples_leaf)을 통한 과적합 해결: GridSearchCV","metadata":{"id":"hmgtmjK5VlSb"}},{"cell_type":"code","source":"# grid_search 함수를 만듭니다.\ndef grid_search(params, reg=DecisionTreeRegressor(random_state=2)):\n\n    # GridSearchCV 객체를 만듭니다.\n    grid_reg = GridSearchCV(\n        reg, params, scoring=\"neg_mean_squared_error\", cv=5, n_jobs=-1\n    )\n\n    # X_train와 y_train에서 그리드 서치를 수행합니다.\n    grid_reg.fit(X_train, y_train)\n\n    # 최상의 매개변수를 추출합니다.\n    best_params = grid_reg.best_params_\n\n    # 최상의 매개변수를 출력합니다.\n    print(\"최상의 매개변수\u001b:\", best_params)\n\n    # 최상의 점수를 계산합니다.\n    best_score = np.sqrt(-grid_reg.best_score_)\n\n    # 최상의 점수를 출력합니다.\n    print(\"훈련 점수: {:.3f}\".format(best_score))\n\n    # 테스트 세트에 대한 예측을 만듭니다.\n    y_pred = grid_reg.predict(X_test)\n\n    # 평균 제곱근 오차를 계산합니다.\n    rmse_test = mean_squared_error(y_test, y_pred) ** 0.5\n\n    # 테스트 세트 점수를 출력합니다.\n    print(\"테스트 점수: {:.3f}\".format(rmse_test))","metadata":{"id":"3AQQdNBnVlSb","trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"grid_search(params={\"min_samples_leaf\": [1, 2, 4, 6, 8, 10, 20, 30]})","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8hNna31VlSc","outputId":"8a8042f9-0115-4c03-d7bb-bf4809273a30","scrolled":true,"trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"grid_search(\n    params={\n        \"max_depth\": [None, 2, 3, 4, 6, 8, 10, 20],\n        \"min_samples_leaf\": [1, 2, 4, 6, 8, 10, 20, 30],\n    }\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKR-pIH_VlSc","outputId":"ba64af65-4051-4ad8-d903-a8934799e7c8","trusted":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"grid_search(params={\"max_depth\": [6, 7, 8, 9, 10], \"min_samples_leaf\": [3, 5, 7, 9]})","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"850Y4D7sVlSd","outputId":"fb17aa72-8cad-4c99-c636-c7b759cb0078","scrolled":true,"trusted":false},"outputs":[],"execution_count":null}]}